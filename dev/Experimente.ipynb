{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimente.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlO5PYLngmRCinPYF/z2n7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1Englert1/cerf_classification/blob/main/dev/Experimente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fdcIj819KIK"
      },
      "source": [
        "**Doku für CoreNLP unter Stanza**\n",
        "https://stanfordnlp.github.io/stanza/client_properties.html#switching-language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUCRVt3JbI_4"
      },
      "source": [
        "#CoreNLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKOOrXpS48Z"
      },
      "source": [
        "##Set up CoreNLP with Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROMiGAbzS86y",
        "outputId": "b23cc234-2141-4d8d-b862-497aa3018c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "!pip install Stanza"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 133kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 143kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 153kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 174kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 194kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 204kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 215kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 225kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from Stanza) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from Stanza) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Stanza) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from Stanza) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from Stanza) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->Stanza) (50.3.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->Stanza) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->Stanza) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->Stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->Stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->Stanza) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->Stanza) (3.0.4)\n",
            "Installing collected packages: Stanza\n",
            "Successfully installed Stanza-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj61mj2qTAVZ",
        "outputId": "3ed77e1f-217f-4953-d000-1fd0441dffdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import stanza\n",
        "stanza.install_corenlp(dir=\"/content/corenlp\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-19 12:26:21 INFO: Installing CoreNLP package into /content/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [00:19<00:00, 25.5MB/s]\n",
            "2020-10-19 12:26:44 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=/content/corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pFNLBDWZAxx"
      },
      "source": [
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = \"./corenlp\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVLH6ISwZB8G",
        "outputId": "9df5f615-e3d6-418c-9d49-5582b5b96782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "stanza.download_corenlp_models(model='german', version='4.1.0', dir=\"/content/corenlp\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-19 12:26:44 INFO: Downloading german models (version 4.1.0) into directory /content/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-4.1.0-models-german.jar: 100%|██████████| 263M/263M [00:22<00:00, 11.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFidZURwoe-k"
      },
      "source": [
        "##Pattern matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUDdnBpidwMx"
      },
      "source": [
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P51juv0BhWjO",
        "outputId": "de7893e5-9bb6-4782-945f-570382a5a80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\n",
        "client = CoreNLPClient(properties='german',\n",
        "                   annotators='tokenize,ssplit,mwt,pos,parse',\n",
        "                   timeout=300000,\n",
        "                   output_format='text', \n",
        "                   be_quiet=True, \n",
        "                   endpoint='http://localhost:9001',\n",
        "                   memory='8G')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-19 12:27:07 INFO: Using Stanford CoreNLP default properties for: german.  Make sure to have german models jar (available for download here: https://stanfordnlp.github.io/CoreNLP/) in CLASSPATH\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS3J1dy5ktGx",
        "outputId": "9ceb8fe9-671f-42e4-d3d6-e4db40b29ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-19 12:32:46 INFO: Starting server with command: java -Xmx8G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 300000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties german -annotators tokenize,ssplit,mwt,pos,parse -preload -outputFormat text\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lg36uv9lZLX"
      },
      "source": [
        "text1 = \"Hast du dir schon überlegt, ob du morgen zur Deutschstunde gehst?\"\n",
        "text2 = \"Was machst du stattdessen, wenn du nicht zur Deutschstunde gehst?\"\n",
        "text3 = \"Wenn ich nicht zur Deutschstunde gehe, bleibe ich im Bett liegen.\"\n",
        "text4 = \"Peter kommt und Paul geht.\"\n",
        "text5 = \"Wir gehen morgen, falls es nicht regnet, in den Zoo.\"\n",
        "text6 = \"Wird das Wetter morgen besser, gehen wir ins Freibad.\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ePqVp-FBUM"
      },
      "source": [
        "def match_pattern(_pattern, _text):\n",
        "  matches = client.tregex(_text,_pattern)\n",
        "  list = matches['sentences']\n",
        "  for sentence in matches['sentences']:\n",
        "    for match_id in sentence:\n",
        "      print(sentence[match_id]['spanString'])\n",
        "\n",
        "def len_sum_matches(_pattern, _text):\n",
        "  matches = client.tregex(_text,_pattern)\n",
        "  list = matches['sentences']\n",
        "  match_list = []\n",
        "  for sentence in matches['sentences']:\n",
        "    for match_id in sentence:\n",
        "      match_list.append(sentence[match_id]['spanString'])\n",
        "  len_sum = 0\n",
        "  for item in match_list:\n",
        "    len_sum = len_sum + len(item)\n",
        "  return(len_sum)\n",
        "\n",
        "def count_matches(_pattern, _text):\n",
        "  matches = client.tregex(_text,_pattern)\n",
        "  list = matches['sentences']\n",
        "  count_units = 0\n",
        "  for sentence in matches['sentences']:\n",
        "    for match_id in sentence:\n",
        "      count_units = count_units + 1\n",
        "  return(count_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzNlKqIPGR62",
        "outputId": "3ede013a-c56b-4540-cc1c-771ab51dd013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "texts = [text1, text2, text3, text4, text5, text6]\n",
        "for text in texts:\n",
        "  print(\"################Neuer Text#####################\")\n",
        "  print(\"################Text#####################\")\n",
        "  print(text)\n",
        "  print(\"################Tree#####################\")\n",
        "  ann = client.annotate(text)\n",
        "  print(ann.split(\"parse:\",1)[1])\n",
        "\n",
        "  ################test#####################\n",
        "  print(\"\\n###############Test###################\")\n",
        "  pattern = \"CAC|CAVP|CNP|CVP\"\n",
        "  match_pattern(pattern, text)\n",
        "  print(count_matches(pattern, text))\n",
        "\n",
        "\n",
        "  ################T-Units#####################\n",
        "  print(\"\\n###############T-Units###################\")\n",
        "  pattern = \"(S > NUR) | (S >> CS >> NUR)\"\n",
        "  match_pattern(pattern, text)\n",
        "  print(count_matches(pattern, text))\n",
        "\n",
        "  ################Complexe T-Units#####################\n",
        "  print(\"\\n###############Complex T-Units###################\")\n",
        "  pattern = \"S >> (S > (CS > NUR > ROOT) | > (NUR > ROOT)) \"\n",
        "  match_pattern(pattern, text)\n",
        "  print(count_matches(pattern, text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Hast du dir schon überlegt, ob du morgen zur Deutschstunde gehst?\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (S (VERB Hast) (PROPN du) (PRON dir) (ADV schon)\n",
            "      (VP (VERB überlegt) (PUNCT ,)\n",
            "        (S (SCONJ ob) (PROPN du) (ADV morgen)\n",
            "          (VP\n",
            "            (PP (ADP zu) (DET der) (NOUN Deutschstunde))\n",
            "            (VERB gehst)))))\n",
            "    (PUNCT ?)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Hast du dir schon überlegt, ob du morgen zu der Deutschstunde gehst\n",
            "1\n",
            "\n",
            "###############Complex T-Units###################\n",
            "ob du morgen zu der Deutschstunde gehst\n",
            "1\n",
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Was machst du stattdessen, wenn du nicht zur Deutschstunde gehst?\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (S (PRON Was) (VERB machst) (PROPN du) (ADV stattdessen) (PUNCT ,)\n",
            "      (S (SCONJ wenn) (PRON du) (PART nicht)\n",
            "        (VP\n",
            "          (PP (ADP zu) (DET der) (NOUN Deutschstunde))\n",
            "          (VERB gehst))))\n",
            "    (PUNCT ?)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Was machst du stattdessen, wenn du nicht zu der Deutschstunde gehst\n",
            "1\n",
            "\n",
            "###############Complex T-Units###################\n",
            "wenn du nicht zu der Deutschstunde gehst\n",
            "1\n",
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Wenn ich nicht zur Deutschstunde gehe, bleibe ich im Bett liegen.\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (S\n",
            "      (S (SCONJ Wenn) (PRON ich) (PART nicht)\n",
            "        (PP (ADP zu) (DET der) (NOUN Deutschstunde))\n",
            "        (VERB gehe))\n",
            "      (PUNCT ,) (AUX bleibe) (PRON ich)\n",
            "      (PP (ADP in) (DET dem) (NOUN Bett))\n",
            "      (VERB liegen))\n",
            "    (PUNCT .)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Wenn ich nicht zu der Deutschstunde gehe, bleibe ich in dem Bett liegen\n",
            "1\n",
            "\n",
            "###############Complex T-Units###################\n",
            "Wenn ich nicht zu der Deutschstunde gehe\n",
            "1\n",
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Peter kommt und Paul geht.\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (CS\n",
            "      (S (PROPN Peter) (VERB kommt))\n",
            "      (CCONJ und)\n",
            "      (S (PROPN Paul) (VERB geht)))\n",
            "    (PUNCT .)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Peter kommt\n",
            "Paul geht\n",
            "2\n",
            "\n",
            "###############Complex T-Units###################\n",
            "0\n",
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Wir gehen morgen, falls es nicht regnet, in den Zoo.\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (S (PRON Wir) (VERB gehen) (ADV morgen) (PUNCT ,)\n",
            "      (S (SCONJ falls) (PRON es) (PART nicht) (VERB regnet))\n",
            "      (PUNCT ,)\n",
            "      (PP (ADP in) (DET den) (NOUN Zoo)))\n",
            "    (PUNCT .)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Wir gehen morgen, falls es nicht regnet, in den Zoo\n",
            "1\n",
            "\n",
            "###############Complex T-Units###################\n",
            "falls es nicht regnet\n",
            "1\n",
            "################Neuer Text#####################\n",
            "################Text#####################\n",
            "Wird das Wetter morgen besser, gehen wir ins Freibad.\n",
            "################Tree#####################\n",
            " \n",
            "(ROOT\n",
            "  (NUR\n",
            "    (S\n",
            "      (S (AUX Wird)\n",
            "        (NP (DET das) (NOUN Wetter))\n",
            "        (AP (ADV morgen) (ADJ besser)))\n",
            "      (PUNCT ,) (VERB gehen) (PRON wir)\n",
            "      (PP (ADP in) (DET das) (NOUN Freibad)))\n",
            "    (PUNCT .)))\n",
            "\n",
            "\n",
            "\n",
            "###############Test###################\n",
            "0\n",
            "\n",
            "###############T-Units###################\n",
            "Wird das Wetter morgen besser, gehen wir in das Freibad\n",
            "1\n",
            "\n",
            "###############Complex T-Units###################\n",
            "Wird das Wetter morgen besser\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuW42hfSk4kf",
        "outputId": "73ead3f1-fcc1-405a-9fc7-eeddb767a5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "client.stop()\n",
        "\n",
        "time.sleep(10)\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    180 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    182 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6bUrX4dbQC1"
      },
      "source": [
        "#Berkeley Neural Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1evku1BnbX7E"
      },
      "source": [
        "##Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNf3MOR4bWGT",
        "outputId": "f5d68dab-444d-497b-caaa-a17204101197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LytiX_NZbeEr",
        "outputId": "7ca8e542-4adc-4565-b36f-1eba4beff80e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install benepar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting benepar\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/7b/6cd9c60e1613a5ad388b4f883fa2aeaddcd8a7ad0a8d5ed87e0d23f159d8/benepar-0.1.2.tar.gz (72kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from benepar) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from benepar) (1.18.5)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.6/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2->benepar) (1.15.0)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.1.2-cp36-cp36m-linux_x86_64.whl size=104471 sha256=3c560ccd9acfc97b34e20894eaaaa923980d4548d98f258dd73c9ca0cb5efd50\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/f5/06/d88543b19a9b326007d7538298a139e994b1d2eecb003bf5af\n",
            "Successfully built benepar\n",
            "Installing collected packages: benepar\n",
            "Successfully installed benepar-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpOYA5Hrejs-",
        "outputId": "673f7552-8906-4cfa-def1-2a46a46cc6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 98kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.0)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJnVPMr0CkMQ",
        "outputId": "84bc0b82-506b-42f3-a7d6-0a4c300cd38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install textacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/99/054efc5dea92c84a850639c490541de6cba29bc148debc3c73848c5e64c2/textacy-0.10.1-py3-none-any.whl (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 4.5MB/s \n",
            "\u001b[?25hCollecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/67/1c60da8ba831bfefedb64c78b9f6820bdf58972797c95644ee3191daf27a/cytoolz-0.11.0.tar.gz (477kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Collecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.5)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn<0.24.0,>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.16.0)\n",
            "Requirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.1.1)\n",
            "Collecting jellyfish>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/09/927ae35fc5a9f70abb6cc2c27ee88fc48549f7bc4786c1d4b177c22e997d/jellyfish-0.8.2-cp36-cp36m-manylinux2014_x86_64.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.41.1)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.11.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (50.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.2.0)\n",
            "Building wheels for collected packages: cytoolz\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.0-cp36-cp36m-linux_x86_64.whl size=1225604 sha256=b6974c65d0f1745eb9807bb01d2f229635be7071fe9863e0cfa451e9e0b8cad7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/32/3c/9c9926b510647cacdde744b2c7acdf1ccd5896fbb7f8d5df0c\n",
            "Successfully built cytoolz\n",
            "Installing collected packages: cytoolz, pyphen, jellyfish, textacy\n",
            "Successfully installed cytoolz-0.11.0 jellyfish-0.8.2 pyphen-0.9.5 textacy-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSa9uu2pNqY",
        "outputId": "3bd93d8c-8b3b-4eeb-a33b-a65e496002c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk_tgrep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk_tgrep\n",
            "  Downloading https://files.pythonhosted.org/packages/20/36/3f69546f68f3f820fa186f859e8e13742d5fe24be3e7796464384cfe3590/nltk_tgrep-1.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: nltk>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from nltk_tgrep) (3.2.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from nltk_tgrep) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.0.0->nltk_tgrep) (1.15.0)\n",
            "Installing collected packages: nltk-tgrep\n",
            "Successfully installed nltk-tgrep-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LCytmCUboH0",
        "outputId": "1375c725-b9a7-4ef6-9d09-dd633df9dda0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "from benepar.spacy_plugin import BeneparComponent\n",
        "import nltk\n",
        "import benepar\n",
        "import textacy\n",
        "import nltk_tgrep\n",
        "from nltk.tree import ParentedTree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulf12MLSpiiN",
        "outputId": "41deba5a-d2ea-40d1-a23f-540595b4d366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMwdVDtccGQZ",
        "outputId": "09d3d093-212b-4e34-88e5-9605c34e4dac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m spacy download de\n",
        "benepar.download('benepar_de')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 774kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=a4dc655f0ecff18c8677eaaf6f5db8d2e8b5eae290012f1bd569b085f841fa46\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y14r70gz/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "[nltk_data] Downloading package benepar_de to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1q9F4pw12ei"
      },
      "source": [
        "##Pattern matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDbzLT9LppZL"
      },
      "source": [
        "text = \"Hast du dir schon überlegt, ob du morgen zur Deutschstunde gehst?\"\n",
        "text2 = \"Was machst du stattdessen, wenn du nicht zur Deutschstunde gehst?\"\n",
        "text3 = \"Wenn ich nicht zur Deutschstunde gehe, bleibe ich im Bett liegen.\"\n",
        "text4 = \"Peter kommt und Paul geht.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htyoE3nsqBrU",
        "outputId": "6b3bbe6a-60cd-42c5-a7a0-25dac537eebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "parser = benepar.Parser(\"benepar_de\")\n",
        "tree = parser.parse(text)\n",
        "print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "(VROOT\n",
            "  (S\n",
            "    (VAFIN-HD Hast)\n",
            "    (PPER-SB du)\n",
            "    (VP-OC (PPER-DA dir) (ADV-MO schon) (VVPP-HD überlegt)))\n",
            "  ($, ,)\n",
            "  (S-OC\n",
            "    (KOUS-CP ob)\n",
            "    (PPER-SB du)\n",
            "    (ADV-MO morgen)\n",
            "    (PP-MO (APPRART-AC zur) (NN-NK Deutschstunde))\n",
            "    (VVFIN-HD gehst))\n",
            "  ($. ?))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwoFp38S0t4I",
        "outputId": "9610d207-c4a3-42de-c994-8438ba9da96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "tree2 = parser.parse(text2)\n",
        "print(tree2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(VROOT\n",
            "  (S\n",
            "    (PWS-OA Was)\n",
            "    (VVFIN-HD machst)\n",
            "    (PPER-SB du)\n",
            "    (PROAV-MO stattdessen))\n",
            "  ($, ,)\n",
            "  (S-MO\n",
            "    (KOUS-CP wenn)\n",
            "    (PPER-SB du)\n",
            "    (PTKNEG-NG nicht)\n",
            "    (PP-MO (APPRART-AC zur) (NN-NK Deutschstunde))\n",
            "    (VVFIN-HD gehst))\n",
            "  ($. ?))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB5NtPAI0t-v",
        "outputId": "6a4800bb-c56d-48f6-f125-9a07199f8e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "tree3 = parser.parse(text3)\n",
        "print(tree3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(VROOT\n",
            "  (S-MO\n",
            "    (KOUS-CP Wenn)\n",
            "    (PPER-SB ich)\n",
            "    (PTKNEG-NG nicht)\n",
            "    (PP-MO (APPRART-AC zur) (NN-NK Deutschstunde))\n",
            "    (VVFIN-HD gehe))\n",
            "  ($, ,)\n",
            "  (S\n",
            "    (VVFIN-HD bleibe)\n",
            "    (PPER-SB ich)\n",
            "    (VP-OC (PP-MO (APPRART-AC im) (NN-NK Bett)) (VVINF-HD liegen)))\n",
            "  ($. .))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYTnYreq29H_",
        "outputId": "3a89af3e-ca0d-4df3-df1d-f254575c9b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "tree4 = parser.parse(text4)\n",
        "print(tree4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(VROOT\n",
            "  (CS\n",
            "    (S-CJ (NE-SB Peter) (VVFIN-HD kommt))\n",
            "    (KON-CD und)\n",
            "    (S-CJ (NE-SB Paul) (VVFIN-HD geht)))\n",
            "  ($. .))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucVDyr-20Am"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qARNtg0OpsrU",
        "outputId": "748fbfd1-579a-4ff6-c841-edba164b85b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "pattern = 'VROOT < S'\n",
        "match = nltk_tgrep.tgrep_nodes(tree, pattern)\n",
        "print(match)\n",
        "print(len(match))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Tree('VROOT', [Tree('S', [Tree('VAFIN-HD', ['Hast']), Tree('PPER-SB', ['du']), Tree('VP-OC', [Tree('PPER-DA', ['dir']), Tree('ADV-MO', ['schon']), Tree('VVPP-HD', ['überlegt'])])]), Tree('$,', [',']), Tree('S-OC', [Tree('KOUS-CP', ['ob']), Tree('PPER-SB', ['du']), Tree('ADV-MO', ['morgen']), Tree('PP-MO', [Tree('APPRART-AC', ['zur']), Tree('NN-NK', ['Deutschstunde'])]), Tree('VVFIN-HD', ['gehst'])]), Tree('$.', ['?'])])]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2VzAco14Mfv",
        "outputId": "6f46d22a-f241-45f2-b08f-19392cb19234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(nltk_tgrep.tgrep_nodes(tree, pattern)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMFTqrVKb4rR"
      },
      "source": [
        "nlp = spacy.load('de')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deftD4s7CNTk",
        "outputId": "f260185b-a166-45b3-967e-58ef78a886f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "text = \"Tom fragt Maria, ob sie ihm die Wahrheit sagt, aber sie antwortet nicht.\"\n",
        "doc = textacy.make_spacy_doc(text)\n",
        "doc._.preview"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 66.7M/66.7M [00:02<00:00, 29.2MB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator HashingVectorizer from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.22 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Doc(16 tokens: \"Tom fragt Maria, ob sie ihm die Wahrheit sagt, ...\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGwiMYqYCL1s",
        "outputId": "665c6d9e-d5e6-44db-892a-52f5f0195eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "doc = nlp(text)\n",
        "print(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom fragt Maria, ob sie ihm die Wahrheit sagt, aber sie antwortet nicht.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C16LmDaXCCUX",
        "outputId": "82949328-1a19-46e0-c0e3-89705e1eb13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "parser_de = benepar.Parser(\"benepar_de\")\n",
        "pattern = 'CS > /^S/'\n",
        "for sent in sents:\n",
        "  tree = parser_de.parse(str(sent))\n",
        "  print(tree)\n",
        "  print(len(nltk_tgrep.tgrep_nodes(tree, pattern)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d5349405164d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparser_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenepar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"benepar_de\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CS > /^S/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser_de\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sents' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGKska3m-t6E"
      },
      "source": [
        "#Type/Token Ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S670UZvJoV5T",
        "outputId": "a968e3bb-f478-4c91-c3b5-6de46305e006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsb02qoxHbFP",
        "outputId": "3fc281e4-2520-450d-e084-918322b49303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "!pip install textacy"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/99/054efc5dea92c84a850639c490541de6cba29bc148debc3c73848c5e64c2/textacy-0.10.1-py3-none-any.whl (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.16.0)\n",
            "Requirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.41.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.5)\n",
            "Collecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.0.2)\n",
            "Collecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/67/1c60da8ba831bfefedb64c78b9f6820bdf58972797c95644ee3191daf27a/cytoolz-0.11.0.tar.gz (477kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 30.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.18.5)\n",
            "Collecting jellyfish>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/09/927ae35fc5a9f70abb6cc2c27ee88fc48549f7bc4786c1d4b177c22e997d/jellyfish-0.8.2-cp36-cp36m-manylinux2014_x86_64.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<0.24.0,>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2020.6.20)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.11.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.2.0)\n",
            "Building wheels for collected packages: cytoolz\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.0-cp36-cp36m-linux_x86_64.whl size=1225581 sha256=3839f3b6450949ac91a5ad137cf5bb5c6c94b35c977613661c7090d24a97f129\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/32/3c/9c9926b510647cacdde744b2c7acdf1ccd5896fbb7f8d5df0c\n",
            "Successfully built cytoolz\n",
            "Installing collected packages: pyphen, cytoolz, jellyfish, textacy\n",
            "Successfully installed cytoolz-0.11.0 jellyfish-0.8.2 pyphen-0.9.5 textacy-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwHRjVepACQy",
        "outputId": "f2e152c9-6de8-4cda-9646-272efcdbe88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 471kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=db29db25c2ec655fe4e303e7d9f7be3b95835bffe1bcaff688e171acb8e4e573\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a39j7yc6/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWx08DXnAZym"
      },
      "source": [
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.de import German\n",
        "nlp = German()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcbVrUO9JB8W",
        "outputId": "34a8b152-040a-4b27-d26c-cb75edffc225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = \"sehr gefruet auf diser Platz. Deshalb möchte ich mich bewarben. Ich glaube es ist ein Richtung wo ich mich besser Bildet machen könnte. Ich habe auch Ihre Anzeige gelesen. Diese Anzeige gefällt mir so sehr Da gibt alles Information was brauche ich . Jetzt wollte ich meine ProsPeckte geben für Ihre Kenntnis. Ich habe Studium gemacht als Computer Science in Stadt Y in Indien. Denn habe ich zwei Jahre ein Job gehabt in Stadt Z und zuletzt arbeite ich von 01.04.2009 bis Jetzt ein Telekaffe. Ihre Anzeige ist für mich ein Gottest Geseck wenn Sie mich ein Platz riserviren könnte.Ich möchte gerne auch wissen ab wann Beginn dieser Ausbildung, wie viele Stunden Prowoche und Arbeitszeit. Ich möchte vorher Ihn Dankber wenn Sie mich züruck schreiben können. Viellen Dank und viellen Grüßen Frau MeierAnlage.\"\n",
        "text = textacy.preprocessing.remove.remove_punctuation(text)\n",
        "text = textacy.preprocessing.normalize.normalize_whitespace(text)\n",
        "text = textacy.preprocessing.replace.replace_numbers(text)\n",
        "\n",
        "print(text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sehr gefruet auf diser Platz Deshalb möchte ich mich bewarben Ich glaube es ist ein Richtung wo ich mich besser Bildet machen könnte Ich habe auch Ihre Anzeige gelesen Diese Anzeige gefällt mir so sehr Da gibt alles Information was brauche ich Jetzt wollte ich meine ProsPeckte geben für Ihre Kenntnis Ich habe Studium gemacht als Computer Science in Stadt Y in Indien Denn habe ich zwei Jahre ein Job gehabt in Stadt Z und zuletzt arbeite ich von _NUMBER_ _NUMBER_ _NUMBER_ bis Jetzt ein Telekaffe Ihre Anzeige ist für mich ein Gottest Geseck wenn Sie mich ein Platz riserviren könnte Ich möchte gerne auch wissen ab wann Beginn dieser Ausbildung wie viele Stunden Prowoche und Arbeitszeit Ich möchte vorher Ihn Dankber wenn Sie mich züruck schreiben können Viellen Dank und viellen Grüßen Frau MeierAnlage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65Z5kxWBMei",
        "outputId": "61275823-5aec-41cd-c4e5-f159bdc0946b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentence = nlp(text)\n",
        "for word in sentence:\n",
        "  print(word.text)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sehr\n",
            "gefruet\n",
            "auf\n",
            "diser\n",
            "Platz\n",
            "Deshalb\n",
            "möchte\n",
            "ich\n",
            "mich\n",
            "bewarben\n",
            "Ich\n",
            "glaube\n",
            "es\n",
            "ist\n",
            "ein\n",
            "Richtung\n",
            "wo\n",
            "ich\n",
            "mich\n",
            "besser\n",
            "Bildet\n",
            "machen\n",
            "könnte\n",
            "Ich\n",
            "habe\n",
            "auch\n",
            "Ihre\n",
            "Anzeige\n",
            "gelesen\n",
            "Diese\n",
            "Anzeige\n",
            "gefällt\n",
            "mir\n",
            "so\n",
            "sehr\n",
            "Da\n",
            "gibt\n",
            "alles\n",
            "Information\n",
            "was\n",
            "brauche\n",
            "ich\n",
            "Jetzt\n",
            "wollte\n",
            "ich\n",
            "meine\n",
            "ProsPeckte\n",
            "geben\n",
            "für\n",
            "Ihre\n",
            "Kenntnis\n",
            "Ich\n",
            "habe\n",
            "Studium\n",
            "gemacht\n",
            "als\n",
            "Computer\n",
            "Science\n",
            "in\n",
            "Stadt\n",
            "Y\n",
            "in\n",
            "Indien\n",
            "Denn\n",
            "habe\n",
            "ich\n",
            "zwei\n",
            "Jahre\n",
            "ein\n",
            "Job\n",
            "gehabt\n",
            "in\n",
            "Stadt\n",
            "Z\n",
            "und\n",
            "zuletzt\n",
            "arbeite\n",
            "ich\n",
            "von\n",
            "_\n",
            "NUMBER\n",
            "_\n",
            "_\n",
            "NUMBER\n",
            "_\n",
            "_\n",
            "NUMBER\n",
            "_\n",
            "bis\n",
            "Jetzt\n",
            "ein\n",
            "Telekaffe\n",
            "Ihre\n",
            "Anzeige\n",
            "ist\n",
            "für\n",
            "mich\n",
            "ein\n",
            "Gottest\n",
            "Geseck\n",
            "wenn\n",
            "Sie\n",
            "mich\n",
            "ein\n",
            "Platz\n",
            "riserviren\n",
            "könnte\n",
            "Ich\n",
            "möchte\n",
            "gerne\n",
            "auch\n",
            "wissen\n",
            "ab\n",
            "wann\n",
            "Beginn\n",
            "dieser\n",
            "Ausbildung\n",
            "wie\n",
            "viele\n",
            "Stunden\n",
            "Prowoche\n",
            "und\n",
            "Arbeitszeit\n",
            "Ich\n",
            "möchte\n",
            "vorher\n",
            "Ihn\n",
            "Dankber\n",
            "wenn\n",
            "Sie\n",
            "mich\n",
            "züruck\n",
            "schreiben\n",
            "können\n",
            "Viellen\n",
            "Dank\n",
            "und\n",
            "viellen\n",
            "Grüßen\n",
            "Frau\n",
            "MeierAnlage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBPDKsriEM0D",
        "outputId": "ac450741-97f6-46e8-cb31-a4f9b033c34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "uniqueToken = []\n",
        "for word in sentence:\n",
        "  token = word.lemma_\n",
        "  if token not in uniqueToken:\n",
        "    uniqueToken.append(token)\n",
        "print(uniqueToken)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sehr', 'gefruet', 'auf', 'diser', 'Platz', 'Deshalb', 'möchte', 'ich', 'mich', 'bewarben', 'Ich', 'glaube', 'es', 'ist', 'ein', 'Richtung', 'wo', 'besser', 'Bildet', 'machen', 'könnte', 'habe', 'auch', 'Ihre', 'Anzeige', 'gelesen', 'Diese', 'gefällt', 'mir', 'so', 'Da', 'gibt', 'alles', 'Information', 'was', 'brauche', 'Jetzt', 'wollte', 'meine', 'ProsPeckte', 'geben', 'für', 'Kenntnis', 'Studium', 'gemacht', 'als', 'Computer', 'Science', 'in', 'Stadt', 'Y', 'Indien', 'Denn', 'zwei', 'Jahre', 'Job', 'gehabt', 'Z', 'und', 'zuletzt', 'arbeite', 'von', '_', 'NUMBER', 'bis', 'Telekaffe', 'Gottest', 'Geseck', 'wenn', 'Sie', 'riserviren', 'gerne', 'wissen', 'ab', 'wann', 'Beginn', 'dieser', 'Ausbildung', 'wie', 'viele', 'Stunden', 'Prowoche', 'Arbeitszeit', 'vorher', 'Ihn', 'Dankber', 'züruck', 'schreiben', 'können', 'Viellen', 'Dank', 'viellen', 'Grüßen', 'Frau', 'MeierAnlage']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XykZPGGoFZxr"
      },
      "source": [
        "import textacy\n",
        "from textacy import preprocessing"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRR0dDp0F-YS",
        "outputId": "b8617eb9-6466-4b87-d54b-d5bce04bec11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "textacy.load_spacy_lang(\"de\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.de.German at 0x7feda61c0f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894gen-XHxCA",
        "outputId": "6df19af4-1885-4788-a3b6-ba2e2bada597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = textacy.preprocessing.remove.remove_punctuation(text)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Morgen geht es mir nicht so gut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0f5d9YRIMBy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}